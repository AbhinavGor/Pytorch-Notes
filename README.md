# GenAI PyTorch Roadmap

This repository tracks my 10-day intensive roadmap to build strong foundations
in PyTorch and generative models.

The focus is on:
- Core PyTorch: tensors, autograd, modules, optimizers
- Classic ML in PyTorch: linear/logistic regression, MLPs, CNNs
- Generative models: VAE, GANs, diffusion, and transformer-based models

## Contents

| Day | Topic                            | Highlights |
| --- | -------------------------------- | ---------- |
| 01  | Tensors & Basics                 | Tensor ops, broadcasting, autograd basics |
| 02  | Linear Regression                | Custom training loop, MSE loss, SGD |
| 03  | Logistic Regression              | Binary classification, decision boundary |
| 04  | MLP for Classification           | `nn.Module`, activation functions, accuracy metrics |
| 05  | CNN on MNIST                     | Conv layers, pooling, training on GPU |
| 06  | Autoencoder, VAE basics          | Reparameterization trick, ELBO, sampling |
| 07  | GAN on MNIST                     | Generator/Discriminator, adversarial training |
| 08  | Experiment with latent dims      | Self-attention, simple sequence model |
| 09  | B-VAE on MNIST.                  | Forward/reverse process, sampling |